{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import Optional, List, Union\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchmetrics import AverageMeter\n",
    "from torchvision.datasets import MNIST\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is image classification with few good practices.\n",
    "\n",
    "Uses the following frameworks:\n",
    "\n",
    "- PyTorch Lightning\n",
    "- TorchMetrics\n",
    "-"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class MnistDataset(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            batch_size: int,\n",
    "            data_path: str,\n",
    "            val_split: float,\n",
    "            dataloader_num_workers: int = 0,\n",
    "            manual_seed=None,\n",
    "            **_,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.h = 28\n",
    "        self.w = 28\n",
    "        self.dims = (1, self.h, self.w)\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.batch_size = batch_size\n",
    "        self.val_split = val_split\n",
    "        self.num_workers = dataloader_num_workers\n",
    "        self.manual_seed = manual_seed\n",
    "\n",
    "        self.transform_train_val, self.transform_test = self._get_transforms()\n",
    "\n",
    "        self.mnist_train, self.mnist_val, self.mnist_test = None, None, None\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        MNIST(self.data_path, train=True, download=True)\n",
    "        MNIST(self.data_path, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        :param stage: One of {fit, validate, test}. None = all 3\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = MNIST(\n",
    "                self.data_path, train=True, transform=self.transform_train_val\n",
    "            )\n",
    "\n",
    "            full_size = len(mnist_full)\n",
    "            val_size = int(full_size * self.val_split)\n",
    "            generator = None\n",
    "            if self.manual_seed:\n",
    "                generator = torch.Generator().manual_seed(self.manual_seed)\n",
    "\n",
    "            self.mnist_train, self.mnist_val = random_split(\n",
    "                mnist_full,\n",
    "                [full_size - val_size, val_size],\n",
    "                generator=generator,\n",
    "            )\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = MNIST(\n",
    "                self.data_path, train=False, transform=self.transform_test\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.mnist_train,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.mnist_val,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.mnist_test,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def _get_transforms(self):\n",
    "        resize_transform = [\n",
    "            A.PadIfNeeded(\n",
    "                min_height=self.h, min_width=self.w, border_mode=cv2.BORDER_CONSTANT\n",
    "            ),\n",
    "            A.RandomCrop(self.h, self.w),\n",
    "        ]\n",
    "\n",
    "        augmentations = [\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.2),\n",
    "        ]\n",
    "\n",
    "        def _normalizer(image, **_):\n",
    "            return image / 255.0\n",
    "\n",
    "        compatible = [\n",
    "            ToTensorV2(always_apply=True),\n",
    "            A.Lambda(image=_normalizer),\n",
    "        ]\n",
    "\n",
    "        transforms_train_val_ = A.Compose(resize_transform + augmentations + compatible)\n",
    "        transforms_test_ = A.Compose(resize_transform + compatible)\n",
    "\n",
    "        def transforms_train_val(image):\n",
    "            return transforms_train_val_(image=np.array(image))[\"image\"]\n",
    "\n",
    "        def transforms_test(image):\n",
    "            return transforms_test_(image=np.array(image))[\"image\"]\n",
    "\n",
    "        return transforms_train_val, transforms_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.leakyrelu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.leakyrelu(self.batchnorm(self.conv(x)))\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            architecture: List[Union[tuple, str, list]],\n",
    "            in_channels: int,\n",
    "    ):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        layers = []\n",
    "        for module in architecture:\n",
    "            if type(module) is tuple:\n",
    "                layers.append(self._get_cnn_block(module, in_channels))\n",
    "                in_channels = module[1]\n",
    "            elif module == \"M\":\n",
    "                layers.append(\n",
    "                    nn.MaxPool2d(\n",
    "                        kernel_size=(2, 2),\n",
    "                        stride=(2, 2),\n",
    "                    )\n",
    "                )\n",
    "            elif type(module) is list:\n",
    "                for i in range(module[-1]):\n",
    "                    for j in range(len(module) - 1):\n",
    "                        layers.append(self._get_cnn_block(module[j], in_channels))\n",
    "                        in_channels = module[j][1]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_cnn_block(module: tuple, in_channels):\n",
    "        kernel_size, filters, stride, padding = module\n",
    "        return CNNBlock(\n",
    "            in_channels,\n",
    "            filters,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class MnistModel(pl.LightningModule):\n",
    "    def __init__(self, **hp):\n",
    "        super().__init__()\n",
    "        architecture = [\n",
    "            # (kernel_size, filters, stride, padding)\n",
    "            (3, 10, 1, 1),\n",
    "            \"M\",\n",
    "            (3, 20, 1, 1),\n",
    "            \"M\",\n",
    "            # (3, 40, 1, 1),\n",
    "            # \"M\",\n",
    "            # (3, 80, 1, 1),\n",
    "            (3, 10, 1, 0),\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            SimpleCNN(architecture, in_channels=1),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        self.hp = hp\n",
    "        self.save_hyperparameters(hp)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Metrics\n",
    "        self.accuracy_train = pl.metrics.Accuracy()\n",
    "        self.accuracy_val = pl.metrics.Accuracy()\n",
    "        self.loss_train = AverageMeter()\n",
    "        self.loss_val = AverageMeter()\n",
    "        self.precision_train = pl.metrics.Precision()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hp['lr_initial'])\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        preds = self(images)\n",
    "        loss = F.nll_loss(preds, targets)\n",
    "        return {'loss': loss, 'preds': preds, 'inputs': images, 'targets': targets}\n",
    "\n",
    "    def training_step_end(self, outs: dict):\n",
    "        self.loss_train(outs['loss'])\n",
    "        self.accuracy_train(outs[\"preds\"], outs[\"targets\"])\n",
    "        self.log('train/step/accuracy', self.accuracy_train, prog_bar=True)\n",
    "\n",
    "    def training_epoch_end(self, outs: dict):\n",
    "        self.log(\"train/epoch/accuracy\", self.accuracy_train.compute())\n",
    "        self.log(\"train/epoch/loss\", self.loss_train.compute())\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        preds = self(images)\n",
    "        loss = F.nll_loss(preds, targets)\n",
    "        print(float(loss))\n",
    "        return {'loss': loss, 'preds': preds, 'inputs': images, 'targets': targets}\n",
    "\n",
    "    def validation_step_end(self, outs: dict):\n",
    "        self.accuracy_val(outs['preds'], outs['targets'])\n",
    "        self.loss_val(outs['loss'])\n",
    "        self.log('val/step/loss', self.loss_val)\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        self.log('val/epoch/accuracy', self.accuracy_val.compute())\n",
    "        self.log('val/epoch/loss', self.loss_val.compute())\n",
    "        self.loss_val.reset()\n",
    "        print('---')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "def debug1():\n",
    "    config = {\n",
    "        \"data_path\": \"../data\",\n",
    "        \"val_split\": 0.3,\n",
    "        \"batch_size\": 2,\n",
    "        \"output_path\": \"./output\",\n",
    "        \"model_save_frequency\": 5,\n",
    "        \"dataloader_num_workers\": 0,\n",
    "    }\n",
    "    dataset = MnistDataset(**config)\n",
    "\n",
    "    dataset.prepare_data()\n",
    "    dataset.setup()\n",
    "    loader = dataset.train_dataloader()\n",
    "    for image, classes in loader:\n",
    "        print(image.shape, classes.shape)\n",
    "        break\n",
    "\n",
    "    hp = {\n",
    "        \"epochs\": 10,\n",
    "        \"lr_initial\": 0.0001,\n",
    "        \"lr_decay_every\": 30,\n",
    "        \"lr_decay_by\": 0.3,\n",
    "    }\n",
    "    model = MnistModel(**hp, **config)\n",
    "    y = model(image)\n",
    "    print(y.shape)\n",
    "\n",
    "# debug1()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name           | Type             | Params\n",
      "----------------------------------------------------\n",
      "0 | model          | Sequential       | 3.8 K \n",
      "1 | criterion      | CrossEntropyLoss | 0     \n",
      "2 | accuracy_train | Accuracy         | 0     \n",
      "3 | accuracy_val   | Accuracy         | 0     \n",
      "4 | loss_train     | AverageMeter     | 0     \n",
      "5 | loss_val       | AverageMeter     | 0     \n",
      "----------------------------------------------------\n",
      "3.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.8 K     Total params\n",
      "0.015     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "571e170760e646ff8158bb78cbf4f324"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: -1it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec55b4db836f486aae189625690a7e7e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f62970391f774f64aff414509a41acb4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.29658615589141846\n",
      "-4.676443576812744\n",
      "-58.12990188598633\n",
      "-405.2906799316406\n",
      "-2538.5869140625\n",
      "-6.2537760734558105\n",
      "-1050.3878173828125\n",
      "-56.816707611083984\n",
      "-605.817138671875\n",
      "-6223.19482421875\n",
      "-5586.888671875\n",
      "-44293.1875\n",
      "-45210.4375\n",
      "-410548.28125\n",
      "-3862.919189453125\n",
      "-357094.71875\n",
      "-3120593.5\n",
      "-27154936.0\n",
      "-3216931.75\n",
      "-13648.322265625\n",
      "-25783222.0\n",
      "-288246016.0\n",
      "-2196800000.0\n",
      "-1136461.625\n",
      "-17054154752.0\n",
      "-14633737.0\n",
      "-6889960.0\n",
      "-161077296.0\n",
      "-105897288.0\n",
      "-987838016.0\n",
      "-910584896.0\n",
      "-3761172992.0\n",
      "-52593897472.0\n",
      "-4667110912.0\n",
      "-306902204416.0\n",
      "-1158659964928.0\n",
      "-30070768926720.0\n",
      "-14559913967616.0\n",
      "-274606233485312.0\n",
      "-1121148733489152.0\n",
      "-6930872477417472.0\n",
      "-5.898123539277414e+16\n",
      "-8.301683187688407e+17\n",
      "-102088327561216.0\n",
      "-4.448099578935247e+18\n",
      "-6.0849902580100235e+19\n",
      "-6.043649060610297e+19\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train():\n",
    "    hp = {\n",
    "        \"epochs\": 10,\n",
    "        \"lr_initial\": 0.0001,\n",
    "        \"lr_decay_every\": 30,\n",
    "        \"lr_decay_by\": 0.3,\n",
    "    }\n",
    "\n",
    "    config = {\n",
    "        \"data_path\": \"../data\",\n",
    "        \"val_split\": 0.05,\n",
    "        \"batch_size\": 64,\n",
    "        'manual_seed': 2,\n",
    "        \"output_path\": \"./output\",\n",
    "        \"model_save_frequency\": 5,\n",
    "        \"dataloader_num_workers\": 0,\n",
    "    }\n",
    "\n",
    "    dataset = MnistDataset(**config)\n",
    "    model = MnistModel(**hp, **config)\n",
    "    # wandb_logger = WandbLogger(project='classification_test', log_model=True)\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=0,\n",
    "        max_epochs=hp[\"epochs\"],\n",
    "        default_root_dir=config[\"output_path\"],\n",
    "        logger=None  #wandb_logger,\n",
    "    )\n",
    "    # wandb_logger.watch(model)\n",
    "\n",
    "    trainer.fit(model, datamodule=dataset)\n",
    "\n",
    "\n",
    "train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def classic_train():\n",
    "    hp = {\n",
    "        \"epochs\": 10,\n",
    "        \"lr_initial\": 0.00001,\n",
    "        \"lr_decay_every\": 30,\n",
    "        \"lr_decay_by\": 0.3,\n",
    "    }\n",
    "\n",
    "    config = {\n",
    "        \"data_path\": \"../data\",\n",
    "        \"val_split\": 0.05,\n",
    "        \"batch_size\": 64,\n",
    "        'manual_seed': 2,\n",
    "        \"output_path\": \"./output\",\n",
    "        \"model_save_frequency\": 5,\n",
    "        \"dataloader_num_workers\": 0,\n",
    "    }\n",
    "\n",
    "    dataset = MnistDataset(**config)\n",
    "    model = MnistModel(**hp, **config)\n",
    "\n",
    "    dataset.prepare_data()\n",
    "    dataset.setup()\n",
    "    train_loader = dataset.train_dataloader()\n",
    "    test_loader = dataset.test_dataloader()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        images, targets = batch\n",
    "        preds = model(images)\n",
    "        loss = F.nll_loss(preds, targets)\n",
    "        return {'loss': loss, 'preds': preds, 'inputs': images, 'targets': targets}\n",
    "        print(image.shape, classes.shape)\n",
    "        break\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}