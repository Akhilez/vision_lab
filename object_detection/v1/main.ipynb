{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "a very quick implementation of object detection.\n",
    "\n",
    "\n",
    "1. Get the pascal voc dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from os import makedirs\n",
    "from os.path import join\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.datasets.voc import VOCDetection\n",
    "from torchvision.models import detection\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.transforms import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2387: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "VOC_CLASSES = [\n",
    "    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
    "    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
    "    'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "\n",
    "HEIGHT = 448\n",
    "WIDTH = 448\n",
    "\n",
    "\n",
    "albument_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=HEIGHT, width=WIDTH, always_apply=True),\n",
    "        # A.RandomCrop(width=WIDTH, height=HEIGHT),\n",
    "        # A.HorizontalFlip(p=0.5),\n",
    "        # A.RandomBrightnessContrast(p=0.2),\n",
    "        ToTensorV2(always_apply=True),\n",
    "        A.Lambda(image=lambda x, **kwargs: x / 255.0)\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(\n",
    "        format='pascal_voc',\n",
    "        min_visibility=0.5,\n",
    "        label_fields=['class_labels']\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def transform_targets_for_model(bboxes, classes):\n",
    "    \"\"\"\n",
    "    boxes: FloatTensor[N, 4] x1y1x2y2\n",
    "    labels: Int64Tensor[N]\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'boxes': torch.FloatTensor(bboxes),\n",
    "        'labels': torch.LongTensor(classes),\n",
    "    }\n",
    "\n",
    "\n",
    "def transform_targets_for_augmentation(targets: dict) -> Tuple[List[Tuple[int, int, int, int]], List[int]]:\n",
    "    classes = []\n",
    "    boxes = []\n",
    "    for object in targets['annotation']['object']:\n",
    "        class_index = VOC_CLASSES.index(object['name'])\n",
    "        classes.append(class_index)\n",
    "\n",
    "        box = object['bndbox']\n",
    "        box = tuple(int(box[key]) for key in ['xmin', 'ymin', 'xmax', 'ymax'])\n",
    "        boxes.append(box)\n",
    "\n",
    "    return boxes, classes\n",
    "\n",
    "\n",
    "def transforms_fn(image, targets):\n",
    "    boxes, classes = transform_targets_for_augmentation(targets)\n",
    "\n",
    "    transformed = albument_transforms(\n",
    "        image=np.array(image),\n",
    "        bboxes=boxes,\n",
    "        class_labels=classes,\n",
    "    )\n",
    "\n",
    "    transformed_image = transformed['image']\n",
    "    transformed_bboxes = transformed['bboxes']\n",
    "    transformed_class_labels = transformed['class_labels']\n",
    "\n",
    "    transformed_targets = transform_targets_for_model(\n",
    "        transformed_bboxes, transformed_class_labels\n",
    "    )\n",
    "    return transformed_image, transformed_targets\n",
    "\n",
    "\n",
    "def collate_fn_voc(batch: List[Tuple[torch.Tensor, dict]]) -> Tuple[list, Tuple[list, list]]:\n",
    "    \"\"\"\n",
    "    :param batch: list of tuple of image and and dict targets\n",
    "    :return: images are batched into a tensor, rest are lists\n",
    "    \"\"\"\n",
    "    # batch = [transforms_fn(image, target) for image, target in batch]\n",
    "    images = []\n",
    "    targets = []\n",
    "    for image, target in batch:\n",
    "        images.append(image)\n",
    "        targets.append(target)\n",
    "\n",
    "    images = torch.stack(images)\n",
    "    return images, targets\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "target is of the following shape:\n",
    "\n",
    "```yaml\n",
    "\n",
    "annotation:\n",
    "  filename: 2009_004972.jpg\n",
    "  folder: VOC2012\n",
    "  object:\n",
    "    - name: bicycle\n",
    "      bndbox:\n",
    "        xmax: 471\n",
    "        xmin: 54\n",
    "        ymax: 336\n",
    "        ymin: 39\n",
    "      difficult: 0\n",
    "      occluded: 0\n",
    "      pose: Left\n",
    "      trucated: 0\n",
    "  segmented: 0\n",
    "  size:\n",
    "    depth: 3\n",
    "    height: 375\n",
    "    width: 500\n",
    "  source:\n",
    "    annotation: PASCAL VOC2009\n",
    "    database: The VOC2009 Database\n",
    "    image: flickr\n",
    "```\n",
    "\n",
    "But it needs to be in this shape:\n",
    "\n",
    "```yaml\n",
    "boxese: FloatTensor[N, 4] x1y1x2y2\n",
    "labels: Int64Tensor[N]\n",
    "image_id:\n",
    "area:\n",
    "iscrowd:\n",
    "masks:\n",
    "keypoints:\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "class DetectionMetrics:\n",
    "    \"\"\"\n",
    "    This class keeps track of all the metrics during training and evaluation.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.metrics_to_track = [\n",
    "            #'accuracy',\n",
    "            #'iou',\n",
    "        ]\n",
    "        self.epoch_metrics = {key: 0.0 for key in self.metrics_to_track}\n",
    "        self.n_batches = 0\n",
    "\n",
    "    def step_batch(\n",
    "        self,\n",
    "        **other,\n",
    "    ):\n",
    "        batch_metrics = other\n",
    "\n",
    "        self._log_batch(batch_metrics)\n",
    "        return batch_metrics\n",
    "\n",
    "    def step_epoch(self) -> dict:\n",
    "        for key in self.epoch_metrics:\n",
    "            self.epoch_metrics[key] /= self.n_batches\n",
    "            metrics = deepcopy(self.epoch_metrics)\n",
    "            self.clear()\n",
    "            return metrics\n",
    "\n",
    "    def _log_batch(self, batch_metrics: dict):\n",
    "        for key in batch_metrics:\n",
    "            if key not in self.epoch_metrics:\n",
    "                self.epoch_metrics[key] = 0\n",
    "            self.epoch_metrics[key] += float(batch_metrics[key])\n",
    "        self.n_batches += 1\n",
    "\n",
    "    def clear(self):\n",
    "        self.epoch_metrics = {key: 0.0 for key in self.metrics_to_track}\n",
    "        self.n_batches = 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_model(num_classes: int):\n",
    "\n",
    "    backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n",
    "    backbone.out_channels = 1280\n",
    "\n",
    "    anchor_generator = AnchorGenerator(\n",
    "        sizes=((64, 128, 256),),\n",
    "        aspect_ratios=((1.0,),)\n",
    "    )\n",
    "\n",
    "    roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
    "        featmap_names=['0'],\n",
    "        output_size=7,\n",
    "        sampling_ratio=2\n",
    "    )\n",
    "\n",
    "    model = FasterRCNN(\n",
    "        backbone,\n",
    "        num_classes=2,\n",
    "        rpn_anchor_generator=anchor_generator,\n",
    "        box_roi_pool=roi_pooler\n",
    "    )\n",
    "\n",
    "    num_classes = num_classes\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "\n",
    "\n",
    "def _save_model(model, cfg: dict, postfix=None):\n",
    "    postfix = f\"__{postfix}\" if postfix is not None else \"\"\n",
    "    file_name = f\"model{postfix}.pth\"\n",
    "    checkpoint_path = join(cfg['output_path'], \"checkpoints\", file_name)\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "\n",
    "def evaluate_dataset(model, data_loader, metrics, optimizer):\n",
    "    # TODO: Change this to eval()\n",
    "    model.train()\n",
    "    for images, targets in data_loader:\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        # TODO: I don't know how to do this in eval mode.\n",
    "        losses = model(images)\n",
    "        loss = torch.sum(losses.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        metrics.step_batch(\n",
    "            loss=float(loss),\n",
    "        )\n",
    "    scores = metrics.step_epoch()\n",
    "    return scores\n",
    "\n",
    "\n",
    "def log_metrics(logger, scores: dict, prefix: str, step):\n",
    "    for key in scores:\n",
    "        logger.add_scalar(f'{prefix}/{key}', scores[key], step)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'data_path': './data',\n",
    "    'valset_size': 0.1,\n",
    "    'epochs': 100,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate.initial': 0.0001,\n",
    "    'learning_rate.decay_every': 30,\n",
    "    'learning_rate.decay_by': 0.3,\n",
    "    'output_path': './output',\n",
    "    'model_save_frequency': 5,\n",
    "}\n",
    "\n",
    "makedirs(join(cfg['output_path'], \"checkpoints\"), exist_ok=True)\n",
    "logger = SummaryWriter()\n",
    "metrics = DetectionMetrics()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(\n",
    "    VOCDetection(\n",
    "        root='../data',\n",
    "        year='2012',\n",
    "        image_set='train',\n",
    "        download=False,\n",
    "        transforms=transforms_fn,\n",
    "    ),\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn_voc,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    VOCDetection(\n",
    "        root='../data',\n",
    "        year='2012',\n",
    "        image_set='val',\n",
    "        download=False,\n",
    "        transforms=transforms_fn,\n",
    "    ),\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn_voc,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model = get_model(len(VOC_CLASSES))\n",
    "\n",
    "if cfg.get('checkpoint'):\n",
    "    model.load(cfg['checkpoint'])\n",
    "\n",
    "model = model.float().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=cfg['learning_rate.initial']\n",
    ")\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=cfg['learning_rate.decay_every'],\n",
    "    gamma=cfg['learning_rate.decay_by'],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/2859 [00:01<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Couldn't load custom C++ ops. This can happen if your PyTorch and torchvision versions are incompatible, or if you had errors while compiling torchvision from source. For further information on the compatible versions, check https://github.com/pytorch/vision#installation for the compatibility matrix. Please check your PyTorch version with torch.__version__ and your torchvision version with torchvision.__version__ and verify if they are compatible, and if not please reinstall torchvision so that it matches your PyTorch install.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-a339a2a296d2>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtargets\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mbatches_bar\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m                 \u001B[0mlosses\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m                 \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlosses\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/torchvision/models/detection/generalized_rcnn.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, images, targets)\u001B[0m\n\u001B[1;32m     94\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m             \u001B[0mfeatures\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOrderedDict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'0'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 96\u001B[0;31m         \u001B[0mproposals\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproposal_losses\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrpn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     97\u001B[0m         \u001B[0mdetections\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdetector_losses\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mroi_heads\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproposals\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimages\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimage_sizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m         \u001B[0mdetections\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpostprocess\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdetections\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimages\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimage_sizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moriginal_image_sizes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/torchvision/models/detection/rpn.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, images, features, targets)\u001B[0m\n\u001B[1;32m    354\u001B[0m         \u001B[0mproposals\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbox_coder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpred_bbox_deltas\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0manchors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    355\u001B[0m         \u001B[0mproposals\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mproposals\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mview\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_images\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m4\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 356\u001B[0;31m         \u001B[0mboxes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscores\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfilter_proposals\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mproposals\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mobjectness\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimages\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimage_sizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_anchors_per_level\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    357\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    358\u001B[0m         \u001B[0mlosses\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/torchvision/models/detection/rpn.py\u001B[0m in \u001B[0;36mfilter_proposals\u001B[0;34m(self, proposals, objectness, image_shapes, num_anchors_per_level)\u001B[0m\n\u001B[1;32m    269\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    270\u001B[0m             \u001B[0;31m# non-maximum suppression, independently done per level\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 271\u001B[0;31m             \u001B[0mkeep\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbox_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatched_nms\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mboxes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlvl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnms_thresh\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    272\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    273\u001B[0m             \u001B[0;31m# keep only topk scoring predictions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/torchvision/ops/boxes.py\u001B[0m in \u001B[0;36mbatched_nms\u001B[0;34m(boxes, scores, idxs, iou_threshold)\u001B[0m\n\u001B[1;32m     64\u001B[0m     \u001B[0;31m# Ideally for GPU we'd use a higher threshold\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mboxes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m4_000\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_is_tracing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 66\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_batched_nms_vanilla\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mboxes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0midxs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miou_threshold\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     67\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     68\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0m_batched_nms_coordinate_trick\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mboxes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0midxs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miou_threshold\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/torch/jit/_trace.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1089\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_tracing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1090\u001B[0m             \u001B[0;31m# Not tracing, don't do anything\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1091\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1092\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1093\u001B[0m         \u001B[0mcompiled_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mscript\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwrapper\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__original_fn\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/torchvision/ops/boxes.py\u001B[0m in \u001B[0;36m_batched_nms_vanilla\u001B[0;34m(boxes, scores, idxs, iou_threshold)\u001B[0m\n\u001B[1;32m    100\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mclass_id\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0midxs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m         \u001B[0mcurr_indices\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwhere\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0midxs\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mclass_id\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 102\u001B[0;31m         \u001B[0mcurr_keep_indices\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnms\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mboxes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcurr_indices\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcurr_indices\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miou_threshold\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    103\u001B[0m         \u001B[0mkeep_mask\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcurr_indices\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcurr_keep_indices\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    104\u001B[0m     \u001B[0mkeep_indices\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwhere\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeep_mask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/torchvision/ops/boxes.py\u001B[0m in \u001B[0;36mnms\u001B[0;34m(boxes, scores, iou_threshold)\u001B[0m\n\u001B[1;32m     32\u001B[0m         \u001B[0mby\u001B[0m \u001B[0mNMS\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msorted\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdecreasing\u001B[0m \u001B[0morder\u001B[0m \u001B[0mof\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m     \"\"\"\n\u001B[0;32m---> 34\u001B[0;31m     \u001B[0m_assert_has_ops\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     35\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtorchvision\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnms\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mboxes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miou_threshold\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/torchvision/extension.py\u001B[0m in \u001B[0;36m_assert_has_ops\u001B[0;34m()\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_assert_has_ops\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     61\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0m_has_ops\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 62\u001B[0;31m         raise RuntimeError(\n\u001B[0m\u001B[1;32m     63\u001B[0m             \u001B[0;34m\"Couldn't load custom C++ ops. This can happen if your PyTorch and \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m             \u001B[0;34m\"torchvision versions are incompatible, or if you had errors while compiling \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Couldn't load custom C++ ops. This can happen if your PyTorch and torchvision versions are incompatible, or if you had errors while compiling torchvision from source. For further information on the compatible versions, check https://github.com/pytorch/vision#installation for the compatibility matrix. Please check your PyTorch version with torch.__version__ and your torchvision version with torchvision.__version__ and verify if they are compatible, and if not please reinstall torchvision so that it matches your PyTorch install."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for epoch in range(cfg['epochs']):\n",
    "        model.train()\n",
    "        with tqdm(train_loader, unit=\"batch\") as batches_bar:\n",
    "            batches_bar.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "            for images, targets in batches_bar:\n",
    "                losses = model(images, targets)\n",
    "                loss = torch.sum(losses.values())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # -------- Metrics ------------\n",
    "\n",
    "                batch_metrics = metrics.step_batch(\n",
    "                    loss=float(loss),\n",
    "                    learning_rate=float(lr_scheduler.get_last_lr()[0]),\n",
    "                    **losses\n",
    "                )\n",
    "                batches_bar.set_postfix(\n",
    "                    loss=batch_metrics['loss'],\n",
    "                )\n",
    "\n",
    "        lr_scheduler.step()\n",
    "        if (epoch + 1) % cfg['model_save_frequency'] == 0:\n",
    "            _save_model(model, cfg, epoch)\n",
    "\n",
    "        scores = metrics.step_epoch()\n",
    "        log_metrics(logger, scores, 'train', epoch)\n",
    "\n",
    "        test_scores = evaluate_dataset(model, test_loader, metrics, optimizer)\n",
    "        log_metrics(logger, test_scores, 'val', epoch)\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopping early.\")\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "_save_model(model, cfg)\n",
    "test_scores = evaluate_dataset(model, test_loader, metrics, optimizer)\n",
    "logger.add_hparams(cfg, test_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}