{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The code is available on my GitHub: https://github.com/Akhilez/vision_lab/blob/master/companies/bungee/main.ipynb\n",
    "\n",
    "The logs are available on my wandb experiment: https://wandb.ai/akhilez/bungee_test?workspace=user-akhilez\n",
    "\n",
    "Hacker rank does not have the required packages installed, so I'm submitting this notebook instead.\n",
    "\n",
    "I could try various different hyperparameters to get the best accuracy, but didn't find enough time for experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics import AverageMeter, MetricCollection, Accuracy, Precision, Recall"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, is_test=False):\n",
    "        self.data = data\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data.iloc[index]\n",
    "        image = data[:294]\n",
    "        classes = data[294:]\n",
    "\n",
    "        image = torch.from_numpy(np.array(image)).float()\n",
    "        if not self.is_test:\n",
    "            classes = torch.tensor(np.array(classes).argmax(axis=0)).long()\n",
    "            return image, classes\n",
    "\n",
    "        return image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class ImageDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size: int,\n",
    "        val_split: float,\n",
    "        **_,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.h = 28\n",
    "        self.w = 28\n",
    "        self.dims = (1, self.h, self.w)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.val_split = val_split\n",
    "\n",
    "        self.data_train, self.data_val, self.data_test = None, None, None\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        data_full = pd.read_csv('./train.csv', header=None)\n",
    "        data_train, data_val = train_test_split(data_full, test_size=self.val_split)\n",
    "        self.data_train = ImageDataset(data_train)\n",
    "        self.data_val = ImageDataset(data_val)\n",
    "\n",
    "        data_test = pd.read_csv('./test.csv', header=None)\n",
    "        self.data_test = ImageDataset(data_test, is_test=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.data_train,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.data_val,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.data_test,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class LinearBlock(nn.Sequential):\n",
    "    def __init__(self, in_units: int, out_units: int):\n",
    "        super().__init__(\n",
    "            nn.Linear(in_units, out_units),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "\n",
    "\n",
    "class ImageModel(pl.LightningModule):\n",
    "    def __init__(self, **hp):\n",
    "        super().__init__()\n",
    "        self.num_classes = 6\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            LinearBlock(294, 500),\n",
    "            LinearBlock(500, self.num_classes),\n",
    "        )\n",
    "\n",
    "        self.hp = hp\n",
    "        self.save_hyperparameters(hp)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Metrics\n",
    "        self.loss_train = AverageMeter()\n",
    "        self.loss_val = AverageMeter()\n",
    "        self.metrics_train = MetricCollection({\n",
    "            'accuracy': Accuracy(),\n",
    "            'precision': Precision(average='macro', num_classes=self.num_classes),\n",
    "            'recall': Recall(average='macro', num_classes=self.num_classes)\n",
    "        }, prefix='train/')\n",
    "        self.metrics_val = self.metrics_train.clone(prefix='val/')\n",
    "        self.preds_test = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hp[\"lr_initial\"])\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer,\n",
    "            step_size=self.hp['lr_decay_every'],\n",
    "            gamma=self.hp['lr_decay_by'],\n",
    "        )\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': lr_scheduler,\n",
    "                'interval': 'epoch',\n",
    "                \"frequency\": 1,\n",
    "                \"name\": \"learning_rate\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        preds = self(images)\n",
    "        loss = self.criterion(preds, targets)\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"preds\": preds.detach(),\n",
    "            \"inputs\": images,\n",
    "            \"targets\": targets,\n",
    "        }\n",
    "\n",
    "    def training_step_end(self, outs: dict):\n",
    "        self.loss_train(outs[\"loss\"])\n",
    "        self.metrics_train(outs[\"preds\"], outs[\"targets\"])\n",
    "        self.log(\"train/accuracy_step\", self.metrics_train['accuracy'], prog_bar=True)\n",
    "\n",
    "    def training_epoch_end(self, outs: dict):\n",
    "        self.log(\"train/loss\", self.loss_train.compute())\n",
    "        self.log_dict(self.metrics_train.compute())\n",
    "        self.log('learning_rate', self.lr_schedulers().get_last_lr()[0])\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        preds = self(images)\n",
    "        loss = self.criterion(preds, targets)\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"preds\": preds.detach(),\n",
    "            \"inputs\": images,\n",
    "            \"targets\": targets,\n",
    "        }\n",
    "\n",
    "    def validation_step_end(self, outs: dict):\n",
    "        self.metrics_val(outs[\"preds\"], outs[\"targets\"])\n",
    "        self.loss_val(outs[\"loss\"])\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        self.log_dict(self.metrics_val.compute())\n",
    "        self.log(\"val/loss\", self.loss_val.compute())\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        preds = self(batch)\n",
    "        preds = preds.detach().argmax(dim=1)\n",
    "        return preds\n",
    "\n",
    "    def test_step_end(self, preds):\n",
    "        for pred in preds:\n",
    "            self.preds_test.append(int(pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_predictions(preds):\n",
    "    with open('./prediction.csv', 'w') as output:\n",
    "        for pred in preds:\n",
    "            out = list(range(6))\n",
    "            out[pred] = 1\n",
    "            output.write(','.join(out) + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | Sequential       | 150 K \n",
      "1 | criterion     | CrossEntropyLoss | 0     \n",
      "2 | loss_train    | AverageMeter     | 0     \n",
      "3 | loss_val      | AverageMeter     | 0     \n",
      "4 | metrics_train | MetricCollection | 0     \n",
      "5 | metrics_val   | MetricCollection | 0     \n",
      "---------------------------------------------------\n",
      "150 K     Trainable params\n",
      "0         Non-trainable params\n",
      "150 K     Total params\n",
      "0.602     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5de3044d6174912a8a174360313c687"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:326: UserWarning: The number of training samples (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: -1it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54e943d94ff24a4e8da598bd46f5ef34"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c750392195844259b956dda0de8a6ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a83071fd5874ddbbe33720e56d0e2b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hp = {\n",
    "    \"epochs\": 200,\n",
    "    \"lr_initial\": 0.0001,\n",
    "    \"lr_decay_every\": 20,\n",
    "    \"lr_decay_by\": 0.99,\n",
    "}\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 64,\n",
    "    'output_path': './output',\n",
    "    'val_split': 0.1,\n",
    "}\n",
    "\n",
    "dataset = ImageDataModule(**config)\n",
    "model = ImageModel(**hp, **config).float()\n",
    "wandb_logger = WandbLogger(project=\"bungee_test\", log_model=True)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=0,\n",
    "    max_epochs=hp[\"epochs\"],\n",
    "    default_root_dir=config[\"output_path\"],\n",
    "    logger=wandb_logger,\n",
    ")\n",
    "wandb_logger.watch(model)\n",
    "\n",
    "trainer.fit(model, datamodule=dataset)\n",
    "trainer.test(model, datamodule=dataset)\n",
    "save_predictions(model.preds_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 10]\n",
      "[ 0 10]\n",
      "[10]\n",
      "[10]\n",
      "[200]\n"
     ]
    }
   ],
   "source": [
    "x = [ 0, 10, 15]\n",
    "y = [ 0, 10, 20]\n",
    "\n",
    "\n",
    "def closestSquaredDistance(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    diff = np.absolute(y - x)\n",
    "\n",
    "    k = 2\n",
    "    idx = np.argpartition(diff, k)[:k]\n",
    "\n",
    "    xs = x[idx]\n",
    "    ys = y[idx]\n",
    "\n",
    "    print(xs)\n",
    "    print(ys)\n",
    "\n",
    "    print(np.diff(xs))\n",
    "    print(np.diff(ys))\n",
    "\n",
    "    result = np.diff(xs) ** 2 + np.diff(ys) ** 2\n",
    "\n",
    "    return result\n",
    "\n",
    "print(closestSquaredDistance(x, y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}